<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on AesVoy</title>
    <link>https://aestheticvoyager.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on AesVoy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2025 Mahan</copyright>
    <lastBuildDate>Fri, 09 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://aestheticvoyager.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Active Learning</title>
      <link>https://aestheticvoyager.github.io/posts/active-learning/</link>
      <pubDate>Fri, 09 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://aestheticvoyager.github.io/posts/active-learning/</guid>
      <description>Active learning is a powerful technique that can help us automate the labeling process for large datasets. By selecting a subset of the data that is most relevant to the task at hand, active learning can be more efficient than manually labeling every example in a dataset. This can lead to better results and more accurate predictions. In this blog post, I&amp;rsquo;ll walk through the concept of active learning, how it works, and share a step-by-step implementation of how to automate dataset labeling for a text classification task using this method.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/active-learning/feature.jpg" />
    </item>
    
    <item>
      <title>Pioneers of Machine Learning and Artificial Intelligence</title>
      <link>https://aestheticvoyager.github.io/posts/ai_pioneers/</link>
      <pubDate>Wed, 12 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>https://aestheticvoyager.github.io/posts/ai_pioneers/</guid>
      <description>The journey of pioneers in Machine Learning (ML) and Artificial Intelligence (AI) is a remarkable tale of innovation, collaboration, and the relentless pursuit of knowledge.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/ai_pioneers/feature.png" />
    </item>
    
    <item>
      <title>Temporal Difference Learning</title>
      <link>https://aestheticvoyager.github.io/posts/temporaldifferencelearning/</link>
      <pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://aestheticvoyager.github.io/posts/temporaldifferencelearning/</guid>
      <description>Temporal Difference (TD) Learning is a fundamental concept in the field of reinforcement learning, which is a subfield of artificial intelligence (AI). It is particularly powerful for problems where an agent must learn to make decisions over time based on its interactions with an environment. Unlike traditional supervised learning, where a model learns from a fixed dataset, TD Learning enables agents to learn directly from experience, making it well-suited for dynamic and uncertain environments.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/temporaldifferencelearning/featured.jpg" />
    </item>
    
    <item>
      <title>Generative Adversarial Network</title>
      <link>https://aestheticvoyager.github.io/posts/generative-adversarial-network/</link>
      <pubDate>Wed, 29 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://aestheticvoyager.github.io/posts/generative-adversarial-network/</guid>
      <description>A neural network is like a highly sophisticated, multi-layered calculator that learns from data. It consists of numerous “neurons” (tiny calculators) connected in layers, with each layer performing a unique function to help the network make predictions or decisions.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/generative-adversarial-network/featured.jpeg" />
    </item>
    
    <item>
      <title>Variational-Auto-Encoder</title>
      <link>https://aestheticvoyager.github.io/posts/variational-auto-encoder/</link>
      <pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://aestheticvoyager.github.io/posts/variational-auto-encoder/</guid>
      <description>The beauty of VAEs lies in their ability to generate new samples by randomly sampling vectors from this known region and then passing them through the generator part of our model.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/variational-auto-encoder/featured.jpeg" />
    </item>
    
    <item>
      <title>Auto-Encoder</title>
      <link>https://aestheticvoyager.github.io/posts/auto-encoder/</link>
      <pubDate>Mon, 27 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://aestheticvoyager.github.io/posts/auto-encoder/</guid>
      <description>An autoencoder begins its journey by compressing input data into a lower dimension. It then endeavors to reconstruct the original input from this compressed representation.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/auto-encoder/featured.jpeg" />
    </item>
    
  </channel>
</rss>
