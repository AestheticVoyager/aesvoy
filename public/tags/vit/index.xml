<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ViT on Aesvoy</title>
    <link>https://aestheticvoyager.github.io/tags/vit/</link>
    <description>Recent content in ViT on Aesvoy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>sciredomir@tutanota.com (Mahan)</managingEditor>
    <webMaster>sciredomir@tutanota.com (Mahan)</webMaster>
    <copyright>Â© 2025 Mahan</copyright>
    <lastBuildDate>Wed, 10 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://aestheticvoyager.github.io/tags/vit/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>DenseNet: How Connections Revolutionized Deep Learning</title>
      <link>https://aestheticvoyager.github.io/posts/densenet/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/densenet/</guid>
      <description>This series explores DenseNet&amp;rsquo;s revolutionary approach to neural connectivity that solved vanishing gradients and improved feature reuse, examines its mathematical foundations and practical implementation, and discusses how its limitations eventually paved the way for Vision Transformers. We trace the evolution from convolutional networks to hybrid architectures, showing how each innovation built upon previous breakthroughs while addressing their shortcomings in the endless pursuit of more efficient and powerful deep learning models.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/densenet/feature.jpg" />
    </item>
    
    <item>
      <title>From CNNs to Vision Transformers: The Future of Image Recognition</title>
      <link>https://aestheticvoyager.github.io/posts/vit/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/vit/</guid>
      <description>Vision Transformers (ViTs) are redefining image recognition by using Transformer models to capture global context, unlike traditional Convolutional Neural Networks (CNNs) that focus on local features. ViTs excel with large datasets and show impressive scalability and performance.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/vit/featured.png" />
    </item>
    
  </channel>
</rss>
