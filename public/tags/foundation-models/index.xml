<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Foundation Models on Aesvoy</title>
    <link>https://aestheticvoyager.github.io/tags/foundation-models/</link>
    <description>Recent content in Foundation Models on Aesvoy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>sciredomir@tutanota.com (Mahan)</managingEditor>
    <webMaster>sciredomir@tutanota.com (Mahan)</webMaster>
    <copyright>© 2025 Mahan</copyright>
    <lastBuildDate>Tue, 02 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://aestheticvoyager.github.io/tags/foundation-models/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>VGGNet Overview</title>
      <link>https://aestheticvoyager.github.io/posts/vggnet/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/vggnet/</guid>
      <description>VGGNet is a famous deep learning model used in computer vision—essentially, teaching computers to understand images. It was created by researchers at the Visual Geometry Group (VGG) at the University of Oxford. Since its debut in 2014, VGGNet has become one of the key models that helped advance how machines see and recognize objects in photos. At its core, VGGNet is designed to look at images and decide what is in them.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/vggnet/feature.jpg" />
    </item>
    
  </channel>
</rss>
