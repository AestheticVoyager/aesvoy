<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CNN on Aesvoy</title>
    <link>https://aestheticvoyager.github.io/tags/cnn/</link>
    <description>Recent content in CNN on Aesvoy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>sciredomir@tutanota.com (Mahan)</managingEditor>
    <webMaster>sciredomir@tutanota.com (Mahan)</webMaster>
    <copyright>© 2025 Mahan</copyright>
    <lastBuildDate>Wed, 10 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://aestheticvoyager.github.io/tags/cnn/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>DenseNet: How Connections Revolutionized Deep Learning</title>
      <link>https://aestheticvoyager.github.io/posts/densenet/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/densenet/</guid>
      <description>This series explores DenseNet&amp;rsquo;s revolutionary approach to neural connectivity that solved vanishing gradients and improved feature reuse, examines its mathematical foundations and practical implementation, and discusses how its limitations eventually paved the way for Vision Transformers. We trace the evolution from convolutional networks to hybrid architectures, showing how each innovation built upon previous breakthroughs while addressing their shortcomings in the endless pursuit of more efficient and powerful deep learning models.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/densenet/feature.jpg" />
    </item>
    
    <item>
      <title>ResNet Overview and Implementatoin</title>
      <link>https://aestheticvoyager.github.io/posts/resnet/</link>
      <pubDate>Thu, 04 Sep 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/resnet/</guid>
      <description>ResNet model and the seminal paper, &lt;em&gt;Deep Residual Learning for Image Recognition&lt;/em&gt; by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, which won the Best Paper award at CVPR 2016. It is one of the most influential and fundamental papers in the history of deep learning for computer vision.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/resnet/feature.jpg" />
    </item>
    
    <item>
      <title>VGGNet Overview</title>
      <link>https://aestheticvoyager.github.io/posts/vggnet/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/vggnet/</guid>
      <description>VGGNet is a famous deep learning model used in computer vision—essentially, teaching computers to understand images. It was created by researchers at the Visual Geometry Group (VGG) at the University of Oxford. Since its debut in 2014, VGGNet has become one of the key models that helped advance how machines see and recognize objects in photos. At its core, VGGNet is designed to look at images and decide what is in them.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/vggnet/feature.jpg" />
    </item>
    
    <item>
      <title>Gradient-Based Learning Applied to Document Recognition</title>
      <link>https://aestheticvoyager.github.io/posts/lenet-5/</link>
      <pubDate>Sat, 30 Aug 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/lenet-5/</guid>
      <description>LeNet-5 is an early and very influential type of convolutional neural network (CNN) developed by Yann LeCun and his colleagues in 1998, designed mainly to recognize handwritten digits like those in the MNIST dataset. What makes LeNet-5 special is how it combines several clever ideas that allow it to efficiently and accurately understand images despite their complexity—ideas that were crucial stepping stones for today’s deep learning revolution.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/lenet-5/feature.jpeg" />
    </item>
    
    <item>
      <title>From CNNs to Vision Transformers: The Future of Image Recognition</title>
      <link>https://aestheticvoyager.github.io/posts/vit/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/vit/</guid>
      <description>Vision Transformers (ViTs) are redefining image recognition by using Transformer models to capture global context, unlike traditional Convolutional Neural Networks (CNNs) that focus on local features. ViTs excel with large datasets and show impressive scalability and performance.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/vit/featured.png" />
    </item>
    
  </channel>
</rss>
