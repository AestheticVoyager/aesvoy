<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Aesvoy</title>
    <link>https://aestheticvoyager.github.io/tags/ml/</link>
    <description>Recent content in ML on Aesvoy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>sciredomir@tutanota.com (Mahan)</managingEditor>
    <webMaster>sciredomir@tutanota.com (Mahan)</webMaster>
    <copyright>© 2025 Mahan</copyright>
    <lastBuildDate>Tue, 02 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://aestheticvoyager.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>VGGNet Overview</title>
      <link>https://aestheticvoyager.github.io/posts/vggnet/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/vggnet/</guid>
      <description>VGGNet is a famous deep learning model used in computer vision—essentially, teaching computers to understand images. It was created by researchers at the Visual Geometry Group (VGG) at the University of Oxford. Since its debut in 2014, VGGNet has become one of the key models that helped advance how machines see and recognize objects in photos. At its core, VGGNet is designed to look at images and decide what is in them.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/vggnet/feature.jpg" />
    </item>
    
    <item>
      <title>Gradient-Based Learning Applied to Document Recognition</title>
      <link>https://aestheticvoyager.github.io/posts/lenet-5/</link>
      <pubDate>Sat, 30 Aug 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/lenet-5/</guid>
      <description>LeNet-5 is an early and very influential type of convolutional neural network (CNN) developed by Yann LeCun and his colleagues in 1998, designed mainly to recognize handwritten digits like those in the MNIST dataset. What makes LeNet-5 special is how it combines several clever ideas that allow it to efficiently and accurately understand images despite their complexity—ideas that were crucial stepping stones for today’s deep learning revolution.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/lenet-5/feature.jpeg" />
    </item>
    
    <item>
      <title>Pioneers of Machine Learning and Artificial Intelligence</title>
      <link>https://aestheticvoyager.github.io/posts/ai_pioneers/</link>
      <pubDate>Wed, 12 Feb 2025 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/ai_pioneers/</guid>
      <description>The journey of pioneers in Machine Learning (ML) and Artificial Intelligence (AI) is a remarkable tale of innovation, collaboration, and the relentless pursuit of knowledge.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/ai_pioneers/feature.png" />
    </item>
    
    <item>
      <title>Gran Turismo&#39;s Sophy AI</title>
      <link>https://aestheticvoyager.github.io/posts/gt-sophy/</link>
      <pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/gt-sophy/</guid>
      <description>Gran Turismo Sophy is an advanced AI racing agent developed through a collaboration between Sony AI, Polyphony Digital, and Sony Interactive Entertainment. This groundbreaking technology utilizes deep reinforcement learning to master the complexities of competitive racing in the Gran Turismo Sport simulator. Initially starting as an AI that struggled to navigate tracks, Sophy has evolved into a formidable competitor capable of challenging top human drivers by mastering racing tactics, etiquette, and vehicle control.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/gt-sophy/feature.jpg" />
    </item>
    
    <item>
      <title>DeepFake Detection Methods</title>
      <link>https://aestheticvoyager.github.io/posts/deepfakedetection/</link>
      <pubDate>Fri, 09 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/deepfakedetection/</guid>
      <description>In this blog post, we explore the topic of image generators and their detection techniques. I&amp;rsquo;ll discuss various methods for detecting image generators and their manipulations. These include analyzing the visual content of an image, examining its metadata, and using machine learning algorithms to identify patterns in the data.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/deepfakedetection/featured.png" />
    </item>
    
    <item>
      <title>From CNNs to Vision Transformers: The Future of Image Recognition</title>
      <link>https://aestheticvoyager.github.io/posts/vit/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/vit/</guid>
      <description>Vision Transformers (ViTs) are redefining image recognition by using Transformer models to capture global context, unlike traditional Convolutional Neural Networks (CNNs) that focus on local features. ViTs excel with large datasets and show impressive scalability and performance.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/vit/featured.png" />
    </item>
    
    <item>
      <title>imageNet-Computer Vision Backbone</title>
      <link>https://aestheticvoyager.github.io/posts/imagenet/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/imagenet/</guid>
      <description>ImageNet is more than just a dataset. The sheer scale of ImageNet, combined with its detailed labeling, made it essentially the backbone of Computer Vision.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/imagenet/featured.jpg" />
    </item>
    
    <item>
      <title>Transformers &amp; Attention</title>
      <link>https://aestheticvoyager.github.io/posts/attention-transformer/</link>
      <pubDate>Mon, 05 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/attention-transformer/</guid>
      <description>This blog post explains how self-attention and softmax function in Transformer models, crucial for modern NLP. It breaks down how self-attention helps models understand relationships between tokens and how softmax ensures efficient computation and numerical stability.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/attention-transformer/featured.jpg" />
    </item>
    
    <item>
      <title>Diffusion VS Auto-Regressive Models</title>
      <link>https://aestheticvoyager.github.io/posts/diffusion-vs-auto-regressive/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/diffusion-vs-auto-regressive/</guid>
      <description>Generative AI has come a long way, producing stunning images from simple text prompts. But how do Diffusion and Auto-Regressive models work, and why are diffusion models preferred.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/diffusion-vs-auto-regressive/featured.jpg" />
    </item>
    
    <item>
      <title>AlexNet Revolution</title>
      <link>https://aestheticvoyager.github.io/posts/alexnet/</link>
      <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/alexnet/</guid>
      <description>In 2012, the field of artificial intelligence witnessed a seismic shift. The catalyst for this transformation was a deep learning model known as AlexNet.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/alexnet/featured.webp" />
    </item>
    
    <item>
      <title>Generative Adversarial Network</title>
      <link>https://aestheticvoyager.github.io/posts/generative-adversarial-network/</link>
      <pubDate>Wed, 29 May 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/generative-adversarial-network/</guid>
      <description>A neural network is like a highly sophisticated, multi-layered calculator that learns from data. It consists of numerous “neurons” (tiny calculators) connected in layers, with each layer performing a unique function to help the network make predictions or decisions.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/generative-adversarial-network/featured.jpeg" />
    </item>
    
    <item>
      <title>Variational-Auto-Encoder</title>
      <link>https://aestheticvoyager.github.io/posts/variational-auto-encoder/</link>
      <pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/variational-auto-encoder/</guid>
      <description>The beauty of VAEs lies in their ability to generate new samples by randomly sampling vectors from this known region and then passing them through the generator part of our model.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/variational-auto-encoder/featured.jpeg" />
    </item>
    
    <item>
      <title>Auto-Encoder</title>
      <link>https://aestheticvoyager.github.io/posts/auto-encoder/</link>
      <pubDate>Mon, 27 May 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/auto-encoder/</guid>
      <description>An autoencoder begins its journey by compressing input data into a lower dimension. It then endeavors to reconstruct the original input from this compressed representation.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/auto-encoder/featured.jpeg" />
    </item>
    
    <item>
      <title>Less is More Paper Review</title>
      <link>https://aestheticvoyager.github.io/posts/less-is-more/</link>
      <pubDate>Sun, 05 May 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/less-is-more/</guid>
      <description>Less is More: Parameter-Free Text Classification with Gzip offers a novel text classification method using gzip compression, eliminating manual parameter tuning.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/less-is-more/featured.jpeg" />
    </item>
    
    <item>
      <title>Infini-Attention Paper Review</title>
      <link>https://aestheticvoyager.github.io/posts/infini-attention/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/infini-attention/</guid>
      <description>Infini-Attention introduces a novel approach to scaling Transformer models for infinitely long inputs while managing memory and computation.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/infini-attention/featured.png" />
    </item>
    
    <item>
      <title>Softmax</title>
      <link>https://aestheticvoyager.github.io/posts/softmax/</link>
      <pubDate>Wed, 17 Apr 2024 00:00:00 +0000</pubDate>
      <author>sciredomir@tutanota.com (Mahan)</author>
      <guid>https://aestheticvoyager.github.io/posts/softmax/</guid>
      <description>Softmax stands as a pivotal component in neural network architectures, offering a means to convert raw scores into interpretable probabilities.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://aestheticvoyager.github.io/posts/softmax/featured.png" />
    </item>
    
  </channel>
</rss>
